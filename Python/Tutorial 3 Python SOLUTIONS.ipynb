{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4390823c",
   "metadata": {},
   "source": [
    "# Tutorial 3: Working with data types in Python\n",
    "\n",
    "There are 11 Tasks in this notebook (though warning some tasks include more than one task) and 3 sections in this tutorial notebook that you can choose between: \n",
    "\n",
    "1. String data \n",
    "2. Categorical data (and Boolean and Numeric and Missing) which includes some advanced bonus tasks\n",
    "3. Date and time data (and string)\n",
    "\n",
    "The aim of this tutorial notebook is to give you some (guided) hands-on experience working with different data types in Python. Which you can then compare with the approaches to working with these data types in R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45cd9b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is always good practice to load the necessary packages and modules at the start of your document\n",
    "import pandas as pd \n",
    "from pandas.api.types import CategoricalDtype \n",
    "import numpy as np\n",
    "import datetime as dt \n",
    "import re\n",
    "import itertools \n",
    "from dateutil import parser, tz, relativedelta\n",
    "\n",
    "## there is a future warning that looks scary, but does not matter to us at the moment, so this code supresses it\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6204ff66",
   "metadata": {},
   "source": [
    "## 1. String data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e02d1a9",
   "metadata": {},
   "source": [
    "### Task 1 \n",
    "\n",
    "How would you access \"solstice\" in `string0` below in code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef6a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "string0 = \"The summer solstice is on Thursday 20 June 2024\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41719b6b",
   "metadata": {},
   "source": [
    "<details><summary style='color:darkblue'>HINT 1: How to start breaking it down? CLICK HERE TO SEE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "We learned about a function in the Python data types notebook which helps us to identify the index of a string (see section 4). From there, we can use that information to access or *slice* the string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b8aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c1a68",
   "metadata": {},
   "source": [
    "#### Task 1 solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb7a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# first find the index for the word in the string \n",
    "print(string0.index(\"solstice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5078e179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solstice\n"
     ]
    }
   ],
   "source": [
    "# then taking that info slice the string\n",
    "print(string0[11:19])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef007b5",
   "metadata": {},
   "source": [
    "## Task 2 - 6\n",
    "\n",
    "There is a corpus of common words in the R `stringr` package that we will use as our data for this task. \n",
    "\n",
    "The process of importing this data and making it workable for this task is a bit complicated. I have outlined the logical steps below in code and here in plain language.\n",
    "\n",
    "First we need to read in the data. To do so, we use the `pd.read_csv('file.csv')` function from the `pandas` package. `read_csv` reads in data from a csv file automatically as a `pandas` data frame structure. Usually this is what we want (as we will see next week), but in this case `words` is a list, so we will then convert the data structure to a list. But oh no, it is a list within a list! We then need to flatten the list structure and join them to be separated by a space, creating a string that we can work with. You could leave the data structure as a list within a list or indeed as a list, but for the purposes of this week, we are learning how to interact with strings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398eeedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "## my data is in a folder called data. If you do not have the same set up, update the file path accordingly \n",
    "word_data = pd.read_csv('../data/common_words.csv', header = None) # the first row is not a header, so I have specified header = None \n",
    "\n",
    "type(word_data) # indeed words is currently a data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc471272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0\n",
      "0            a\n",
      "1         able\n",
      "2        about\n",
      "3     absolute\n",
      "4       accept\n",
      "..         ...\n",
      "975        yes\n",
      "976  yesterday\n",
      "977        yet\n",
      "978        you\n",
      "979      young\n",
      "\n",
      "[980 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# view the data that has been read in as a pandas data frame \n",
    "print(word_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2f29785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now convert words to a list for this task \n",
    "word_list = word_data.values.tolist()\n",
    "\n",
    "type(word_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef66ff",
   "metadata": {},
   "source": [
    "When reading in data, it is always good practice to print it to make sure it parsed as expected. For this we can use `print()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae651550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a'], ['able'], ['about'], ['absolute'], ['accept'], ['account'], ['achieve'], ['across'], ['act'], ['active'], ['actual'], ['add'], ['address'], ['admit'], ['advertise'], ['affect'], ['afford'], ['after'], ['afternoon'], ['again'], ['against'], ['age'], ['agent'], ['ago'], ['agree'], ['air'], ['all'], ['allow'], ['almost'], ['along'], ['already'], ['alright'], ['also'], ['although'], ['always'], ['america'], ['amount'], ['and'], ['another'], ['answer'], ['any'], ['apart'], ['apparent'], ['appear'], ['apply'], ['appoint'], ['approach'], ['appropriate'], ['area'], ['argue'], ['arm'], ['around'], ['arrange'], ['art'], ['as'], ['ask'], ['associate'], ['assume'], ['at'], ['attend'], ['authority'], ['available'], ['aware'], ['away'], ['awful'], ['baby'], ['back'], ['bad'], ['bag'], ['balance'], ['ball'], ['bank'], ['bar'], ['base'], ['basis'], ['be'], ['bear'], ['beat'], ['beauty'], ['because'], ['become'], ['bed'], ['before'], ['begin'], ['behind'], ['believe'], ['benefit'], ['best'], ['bet'], ['between'], ['big'], ['bill'], ['birth'], ['bit'], ['black'], ['bloke'], ['blood'], ['blow'], ['blue'], ['board'], ['boat'], ['body'], ['book'], ['both'], ['bother'], ['bottle'], ['bottom'], ['box'], ['boy'], ['break'], ['brief'], ['brilliant'], ['bring'], ['britain'], ['brother'], ['budget'], ['build'], ['bus'], ['business'], ['busy'], ['but'], ['buy'], ['by'], ['cake'], ['call'], ['can'], ['car'], ['card'], ['care'], ['carry'], ['case'], ['cat'], ['catch'], ['cause'], ['cent'], ['centre'], ['certain'], ['chair'], ['chairman'], ['chance'], ['change'], ['chap'], ['character'], ['charge'], ['cheap'], ['check'], ['child'], ['choice'], ['choose'], ['Christ'], ['Christmas'], ['church'], ['city'], ['claim'], ['class'], ['clean'], ['clear'], ['client'], ['clock'], ['close'], ['closes'], ['clothe'], ['club'], ['coffee'], ['cold'], ['colleague'], ['collect'], ['college'], ['colour'], ['come'], ['comment'], ['commit'], ['committee'], ['common'], ['community'], ['company'], ['compare'], ['complete'], ['compute'], ['concern'], ['condition'], ['confer'], ['consider'], ['consult'], ['contact'], ['continue'], ['contract'], ['control'], ['converse'], ['cook'], ['copy'], ['corner'], ['correct'], ['cost'], ['could'], ['council'], ['count'], ['country'], ['county'], ['couple'], ['course'], ['court'], ['cover'], ['create'], ['cross'], ['cup'], ['current'], ['cut'], ['dad'], ['danger'], ['date'], ['day'], ['dead'], ['deal'], ['dear'], ['debate'], ['decide'], ['decision'], ['deep'], ['definite'], ['degree'], ['department'], ['depend'], ['describe'], ['design'], ['detail'], ['develop'], ['die'], ['difference'], ['difficult'], ['dinner'], ['direct'], ['discuss'], ['district'], ['divide'], ['do'], ['doctor'], ['document'], ['dog'], ['door'], ['double'], ['doubt'], ['down'], ['draw'], ['dress'], ['drink'], ['drive'], ['drop'], ['dry'], ['due'], ['during'], ['each'], ['early'], ['east'], ['easy'], ['eat'], ['economy'], ['educate'], ['effect'], ['egg'], ['eight'], ['either'], ['elect'], ['electric'], ['eleven'], ['else'], ['employ'], ['encourage'], ['end'], ['engine'], ['english'], ['enjoy'], ['enough'], ['enter'], ['environment'], ['equal'], ['especial'], ['europe'], ['even'], ['evening'], ['ever'], ['every'], ['evidence'], ['exact'], ['example'], ['except'], ['excuse'], ['exercise'], ['exist'], ['expect'], ['expense'], ['experience'], ['explain'], ['express'], ['extra'], ['eye'], ['face'], ['fact'], ['fair'], ['fall'], ['family'], ['far'], ['farm'], ['fast'], ['father'], ['favour'], ['feed'], ['feel'], ['few'], ['field'], ['fight'], ['figure'], ['file'], ['fill'], ['film'], ['final'], ['finance'], ['find'], ['fine'], ['finish'], ['fire'], ['first'], ['fish'], ['fit'], ['five'], ['flat'], ['floor'], ['fly'], ['follow'], ['food'], ['foot'], ['for'], ['force'], ['forget'], ['form'], ['fortune'], ['forward'], ['four'], ['france'], ['free'], ['friday'], ['friend'], ['from'], ['front'], ['full'], ['fun'], ['function'], ['fund'], ['further'], ['future'], ['game'], ['garden'], ['gas'], ['general'], ['germany'], ['get'], ['girl'], ['give'], ['glass'], ['go'], ['god'], ['good'], ['goodbye'], ['govern'], ['grand'], ['grant'], ['great'], ['green'], ['ground'], ['group'], ['grow'], ['guess'], ['guy'], ['hair'], ['half'], ['hall'], ['hand'], ['hang'], ['happen'], ['happy'], ['hard'], ['hate'], ['have'], ['he'], ['head'], ['health'], ['hear'], ['heart'], ['heat'], ['heavy'], ['hell'], ['help'], ['here'], ['high'], ['history'], ['hit'], ['hold'], ['holiday'], ['home'], ['honest'], ['hope'], ['horse'], ['hospital'], ['hot'], ['hour'], ['house'], ['how'], ['however'], ['hullo'], ['hundred'], ['husband'], ['idea'], ['identify'], ['if'], ['imagine'], ['important'], ['improve'], ['in'], ['include'], ['income'], ['increase'], ['indeed'], ['individual'], ['industry'], ['inform'], ['inside'], ['instead'], ['insure'], ['interest'], ['into'], ['introduce'], ['invest'], ['involve'], ['issue'], ['it'], ['item'], ['jesus'], ['job'], ['join'], ['judge'], ['jump'], ['just'], ['keep'], ['key'], ['kid'], ['kill'], ['kind'], ['king'], ['kitchen'], ['knock'], ['know'], ['labour'], ['lad'], ['lady'], ['land'], ['language'], ['large'], ['last'], ['late'], ['laugh'], ['law'], ['lay'], ['lead'], ['learn'], ['leave'], ['left'], ['leg'], ['less'], ['let'], ['letter'], ['level'], ['lie'], ['life'], ['light'], ['like'], ['likely'], ['limit'], ['line'], ['link'], ['list'], ['listen'], ['little'], ['live'], ['load'], ['local'], ['lock'], ['london'], ['long'], ['look'], ['lord'], ['lose'], ['lot'], ['love'], ['low'], ['luck'], ['lunch'], ['machine'], ['main'], ['major'], ['make'], ['man'], ['manage'], ['many'], ['mark'], ['market'], ['marry'], ['match'], ['matter'], ['may'], ['maybe'], ['mean'], ['meaning'], ['measure'], ['meet'], ['member'], ['mention'], ['middle'], ['might'], ['mile'], ['milk'], ['million'], ['mind'], ['minister'], ['minus'], ['minute'], ['miss'], ['mister'], ['moment'], ['monday'], ['money'], ['month'], ['more'], ['morning'], ['most'], ['mother'], ['motion'], ['move'], ['mrs'], ['much'], ['music'], ['must'], ['name'], ['nation'], ['nature'], ['near'], ['necessary'], ['need'], ['never'], ['new'], ['news'], ['next'], ['nice'], ['night'], ['nine'], ['no'], ['non'], ['none'], ['normal'], ['north'], ['not'], ['note'], ['notice'], ['now'], ['number'], ['obvious'], ['occasion'], ['odd'], ['of'], ['off'], ['offer'], ['office'], ['often'], ['okay'], ['old'], ['on'], ['once'], ['one'], ['only'], ['open'], ['operate'], ['opportunity'], ['oppose'], ['or'], ['order'], ['organize'], ['original'], ['other'], ['otherwise'], ['ought'], ['out'], ['over'], ['own'], ['pack'], ['page'], ['paint'], ['pair'], ['paper'], ['paragraph'], ['pardon'], ['parent'], ['park'], ['part'], ['particular'], ['party'], ['pass'], ['past'], ['pay'], ['pence'], ['pension'], ['people'], ['per'], ['percent'], ['perfect'], ['perhaps'], ['period'], ['person'], ['photograph'], ['pick'], ['picture'], ['piece'], ['place'], ['plan'], ['play'], ['please'], ['plus'], ['point'], ['police'], ['policy'], ['politic'], ['poor'], ['position'], ['positive'], ['possible'], ['post'], ['pound'], ['power'], ['practise'], ['prepare'], ['present'], ['press'], ['pressure'], ['presume'], ['pretty'], ['previous'], ['price'], ['print'], ['private'], ['probable'], ['problem'], ['proceed'], ['process'], ['produce'], ['product'], ['programme'], ['project'], ['proper'], ['propose'], ['protect'], ['provide'], ['public'], ['pull'], ['purpose'], ['push'], ['put'], ['quality'], ['quarter'], ['question'], ['quick'], ['quid'], ['quiet'], ['quite'], ['radio'], ['rail'], ['raise'], ['range'], ['rate'], ['rather'], ['read'], ['ready'], ['real'], ['realise'], ['really'], ['reason'], ['receive'], ['recent'], ['reckon'], ['recognize'], ['recommend'], ['record'], ['red'], ['reduce'], ['refer'], ['regard'], ['region'], ['relation'], ['remember'], ['report'], ['represent'], ['require'], ['research'], ['resource'], ['respect'], ['responsible'], ['rest'], ['result'], ['return'], ['rid'], ['right'], ['ring'], ['rise'], ['road'], ['role'], ['roll'], ['room'], ['round'], ['rule'], ['run'], ['safe'], ['sale'], ['same'], ['saturday'], ['save'], ['say'], ['scheme'], ['school'], ['science'], ['score'], ['scotland'], ['seat'], ['second'], ['secretary'], ['section'], ['secure'], ['see'], ['seem'], ['self'], ['sell'], ['send'], ['sense'], ['separate'], ['serious'], ['serve'], ['service'], ['set'], ['settle'], ['seven'], ['sex'], ['shall'], ['share'], ['she'], ['sheet'], ['shoe'], ['shoot'], ['shop'], ['short'], ['should'], ['show'], ['shut'], ['sick'], ['side'], ['sign'], ['similar'], ['simple'], ['since'], ['sing'], ['single'], ['sir'], ['sister'], ['sit'], ['site'], ['situate'], ['six'], ['size'], ['sleep'], ['slight'], ['slow'], ['small'], ['smoke'], ['so'], ['social'], ['society'], ['some'], ['son'], ['soon'], ['sorry'], ['sort'], ['sound'], ['south'], ['space'], ['speak'], ['special'], ['specific'], ['speed'], ['spell'], ['spend'], ['square'], ['staff'], ['stage'], ['stairs'], ['stand'], ['standard'], ['start'], ['state'], ['station'], ['stay'], ['step'], ['stick'], ['still'], ['stop'], ['story'], ['straight'], ['strategy'], ['street'], ['strike'], ['strong'], ['structure'], ['student'], ['study'], ['stuff'], ['stupid'], ['subject'], ['succeed'], ['such'], ['sudden'], ['suggest'], ['suit'], ['summer'], ['sun'], ['sunday'], ['supply'], ['support'], ['suppose'], ['sure'], ['surprise'], ['switch'], ['system'], ['table'], ['take'], ['talk'], ['tape'], ['tax'], ['tea'], ['teach'], ['team'], ['telephone'], ['television'], ['tell'], ['ten'], ['tend'], ['term'], ['terrible'], ['test'], ['than'], ['thank'], ['the'], ['then'], ['there'], ['therefore'], ['they'], ['thing'], ['think'], ['thirteen'], ['thirty'], ['this'], ['thou'], ['though'], ['thousand'], ['three'], ['through'], ['throw'], ['thursday'], ['tie'], ['time'], ['to'], ['today'], ['together'], ['tomorrow'], ['tonight'], ['too'], ['top'], ['total'], ['touch'], ['toward'], ['town'], ['trade'], ['traffic'], ['train'], ['transport'], ['travel'], ['treat'], ['tree'], ['trouble'], ['TRUE'], ['trust'], ['try'], ['tuesday'], ['turn'], ['twelve'], ['twenty'], ['two'], ['type'], ['under'], ['understand'], ['union'], ['unit'], ['unite'], ['university'], ['unless'], ['until'], ['up'], ['upon'], ['use'], ['usual'], ['value'], ['various'], ['very'], ['video'], ['view'], ['village'], ['visit'], ['vote'], ['wage'], ['wait'], ['walk'], ['wall'], ['want'], ['war'], ['warm'], ['wash'], ['waste'], ['watch'], ['water'], ['way'], ['we'], ['wear'], ['wednesday'], ['wee'], ['week'], ['weigh'], ['welcome'], ['well'], ['west'], ['what'], ['when'], ['where'], ['whether'], ['which'], ['while'], ['white'], ['who'], ['whole'], ['why'], ['wide'], ['wife'], ['will'], ['win'], ['wind'], ['window'], ['wish'], ['with'], ['within'], ['without'], ['woman'], ['wonder'], ['wood'], ['word'], ['work'], ['world'], ['worry'], ['worse'], ['worth'], ['would'], ['write'], ['wrong'], ['year'], ['yes'], ['yesterday'], ['yet'], ['you'], ['young']]\n"
     ]
    }
   ],
   "source": [
    "# to see the list within a list structure if you are interested\n",
    "print(word_list)\n",
    "\n",
    "# notice we now have lists within a list [[...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ec85a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'able', 'about', 'absolute', 'accept', 'account', 'achieve', 'across', 'act', 'active', 'actual', 'add', 'address', 'admit', 'advertise', 'affect', 'afford', 'after', 'afternoon', 'again', 'against', 'age', 'agent', 'ago', 'agree', 'air', 'all', 'allow', 'almost', 'along', 'already', 'alright', 'also', 'although', 'always', 'america', 'amount', 'and', 'another', 'answer', 'any', 'apart', 'apparent', 'appear', 'apply', 'appoint', 'approach', 'appropriate', 'area', 'argue', 'arm', 'around', 'arrange', 'art', 'as', 'ask', 'associate', 'assume', 'at', 'attend', 'authority', 'available', 'aware', 'away', 'awful', 'baby', 'back', 'bad', 'bag', 'balance', 'ball', 'bank', 'bar', 'base', 'basis', 'be', 'bear', 'beat', 'beauty', 'because', 'become', 'bed', 'before', 'begin', 'behind', 'believe', 'benefit', 'best', 'bet', 'between', 'big', 'bill', 'birth', 'bit', 'black', 'bloke', 'blood', 'blow', 'blue', 'board', 'boat', 'body', 'book', 'both', 'bother', 'bottle', 'bottom', 'box', 'boy', 'break', 'brief', 'brilliant', 'bring', 'britain', 'brother', 'budget', 'build', 'bus', 'business', 'busy', 'but', 'buy', 'by', 'cake', 'call', 'can', 'car', 'card', 'care', 'carry', 'case', 'cat', 'catch', 'cause', 'cent', 'centre', 'certain', 'chair', 'chairman', 'chance', 'change', 'chap', 'character', 'charge', 'cheap', 'check', 'child', 'choice', 'choose', 'Christ', 'Christmas', 'church', 'city', 'claim', 'class', 'clean', 'clear', 'client', 'clock', 'close', 'closes', 'clothe', 'club', 'coffee', 'cold', 'colleague', 'collect', 'college', 'colour', 'come', 'comment', 'commit', 'committee', 'common', 'community', 'company', 'compare', 'complete', 'compute', 'concern', 'condition', 'confer', 'consider', 'consult', 'contact', 'continue', 'contract', 'control', 'converse', 'cook', 'copy', 'corner', 'correct', 'cost', 'could', 'council', 'count', 'country', 'county', 'couple', 'course', 'court', 'cover', 'create', 'cross', 'cup', 'current', 'cut', 'dad', 'danger', 'date', 'day', 'dead', 'deal', 'dear', 'debate', 'decide', 'decision', 'deep', 'definite', 'degree', 'department', 'depend', 'describe', 'design', 'detail', 'develop', 'die', 'difference', 'difficult', 'dinner', 'direct', 'discuss', 'district', 'divide', 'do', 'doctor', 'document', 'dog', 'door', 'double', 'doubt', 'down', 'draw', 'dress', 'drink', 'drive', 'drop', 'dry', 'due', 'during', 'each', 'early', 'east', 'easy', 'eat', 'economy', 'educate', 'effect', 'egg', 'eight', 'either', 'elect', 'electric', 'eleven', 'else', 'employ', 'encourage', 'end', 'engine', 'english', 'enjoy', 'enough', 'enter', 'environment', 'equal', 'especial', 'europe', 'even', 'evening', 'ever', 'every', 'evidence', 'exact', 'example', 'except', 'excuse', 'exercise', 'exist', 'expect', 'expense', 'experience', 'explain', 'express', 'extra', 'eye', 'face', 'fact', 'fair', 'fall', 'family', 'far', 'farm', 'fast', 'father', 'favour', 'feed', 'feel', 'few', 'field', 'fight', 'figure', 'file', 'fill', 'film', 'final', 'finance', 'find', 'fine', 'finish', 'fire', 'first', 'fish', 'fit', 'five', 'flat', 'floor', 'fly', 'follow', 'food', 'foot', 'for', 'force', 'forget', 'form', 'fortune', 'forward', 'four', 'france', 'free', 'friday', 'friend', 'from', 'front', 'full', 'fun', 'function', 'fund', 'further', 'future', 'game', 'garden', 'gas', 'general', 'germany', 'get', 'girl', 'give', 'glass', 'go', 'god', 'good', 'goodbye', 'govern', 'grand', 'grant', 'great', 'green', 'ground', 'group', 'grow', 'guess', 'guy', 'hair', 'half', 'hall', 'hand', 'hang', 'happen', 'happy', 'hard', 'hate', 'have', 'he', 'head', 'health', 'hear', 'heart', 'heat', 'heavy', 'hell', 'help', 'here', 'high', 'history', 'hit', 'hold', 'holiday', 'home', 'honest', 'hope', 'horse', 'hospital', 'hot', 'hour', 'house', 'how', 'however', 'hullo', 'hundred', 'husband', 'idea', 'identify', 'if', 'imagine', 'important', 'improve', 'in', 'include', 'income', 'increase', 'indeed', 'individual', 'industry', 'inform', 'inside', 'instead', 'insure', 'interest', 'into', 'introduce', 'invest', 'involve', 'issue', 'it', 'item', 'jesus', 'job', 'join', 'judge', 'jump', 'just', 'keep', 'key', 'kid', 'kill', 'kind', 'king', 'kitchen', 'knock', 'know', 'labour', 'lad', 'lady', 'land', 'language', 'large', 'last', 'late', 'laugh', 'law', 'lay', 'lead', 'learn', 'leave', 'left', 'leg', 'less', 'let', 'letter', 'level', 'lie', 'life', 'light', 'like', 'likely', 'limit', 'line', 'link', 'list', 'listen', 'little', 'live', 'load', 'local', 'lock', 'london', 'long', 'look', 'lord', 'lose', 'lot', 'love', 'low', 'luck', 'lunch', 'machine', 'main', 'major', 'make', 'man', 'manage', 'many', 'mark', 'market', 'marry', 'match', 'matter', 'may', 'maybe', 'mean', 'meaning', 'measure', 'meet', 'member', 'mention', 'middle', 'might', 'mile', 'milk', 'million', 'mind', 'minister', 'minus', 'minute', 'miss', 'mister', 'moment', 'monday', 'money', 'month', 'more', 'morning', 'most', 'mother', 'motion', 'move', 'mrs', 'much', 'music', 'must', 'name', 'nation', 'nature', 'near', 'necessary', 'need', 'never', 'new', 'news', 'next', 'nice', 'night', 'nine', 'no', 'non', 'none', 'normal', 'north', 'not', 'note', 'notice', 'now', 'number', 'obvious', 'occasion', 'odd', 'of', 'off', 'offer', 'office', 'often', 'okay', 'old', 'on', 'once', 'one', 'only', 'open', 'operate', 'opportunity', 'oppose', 'or', 'order', 'organize', 'original', 'other', 'otherwise', 'ought', 'out', 'over', 'own', 'pack', 'page', 'paint', 'pair', 'paper', 'paragraph', 'pardon', 'parent', 'park', 'part', 'particular', 'party', 'pass', 'past', 'pay', 'pence', 'pension', 'people', 'per', 'percent', 'perfect', 'perhaps', 'period', 'person', 'photograph', 'pick', 'picture', 'piece', 'place', 'plan', 'play', 'please', 'plus', 'point', 'police', 'policy', 'politic', 'poor', 'position', 'positive', 'possible', 'post', 'pound', 'power', 'practise', 'prepare', 'present', 'press', 'pressure', 'presume', 'pretty', 'previous', 'price', 'print', 'private', 'probable', 'problem', 'proceed', 'process', 'produce', 'product', 'programme', 'project', 'proper', 'propose', 'protect', 'provide', 'public', 'pull', 'purpose', 'push', 'put', 'quality', 'quarter', 'question', 'quick', 'quid', 'quiet', 'quite', 'radio', 'rail', 'raise', 'range', 'rate', 'rather', 'read', 'ready', 'real', 'realise', 'really', 'reason', 'receive', 'recent', 'reckon', 'recognize', 'recommend', 'record', 'red', 'reduce', 'refer', 'regard', 'region', 'relation', 'remember', 'report', 'represent', 'require', 'research', 'resource', 'respect', 'responsible', 'rest', 'result', 'return', 'rid', 'right', 'ring', 'rise', 'road', 'role', 'roll', 'room', 'round', 'rule', 'run', 'safe', 'sale', 'same', 'saturday', 'save', 'say', 'scheme', 'school', 'science', 'score', 'scotland', 'seat', 'second', 'secretary', 'section', 'secure', 'see', 'seem', 'self', 'sell', 'send', 'sense', 'separate', 'serious', 'serve', 'service', 'set', 'settle', 'seven', 'sex', 'shall', 'share', 'she', 'sheet', 'shoe', 'shoot', 'shop', 'short', 'should', 'show', 'shut', 'sick', 'side', 'sign', 'similar', 'simple', 'since', 'sing', 'single', 'sir', 'sister', 'sit', 'site', 'situate', 'six', 'size', 'sleep', 'slight', 'slow', 'small', 'smoke', 'so', 'social', 'society', 'some', 'son', 'soon', 'sorry', 'sort', 'sound', 'south', 'space', 'speak', 'special', 'specific', 'speed', 'spell', 'spend', 'square', 'staff', 'stage', 'stairs', 'stand', 'standard', 'start', 'state', 'station', 'stay', 'step', 'stick', 'still', 'stop', 'story', 'straight', 'strategy', 'street', 'strike', 'strong', 'structure', 'student', 'study', 'stuff', 'stupid', 'subject', 'succeed', 'such', 'sudden', 'suggest', 'suit', 'summer', 'sun', 'sunday', 'supply', 'support', 'suppose', 'sure', 'surprise', 'switch', 'system', 'table', 'take', 'talk', 'tape', 'tax', 'tea', 'teach', 'team', 'telephone', 'television', 'tell', 'ten', 'tend', 'term', 'terrible', 'test', 'than', 'thank', 'the', 'then', 'there', 'therefore', 'they', 'thing', 'think', 'thirteen', 'thirty', 'this', 'thou', 'though', 'thousand', 'three', 'through', 'throw', 'thursday', 'tie', 'time', 'to', 'today', 'together', 'tomorrow', 'tonight', 'too', 'top', 'total', 'touch', 'toward', 'town', 'trade', 'traffic', 'train', 'transport', 'travel', 'treat', 'tree', 'trouble', 'TRUE', 'trust', 'try', 'tuesday', 'turn', 'twelve', 'twenty', 'two', 'type', 'under', 'understand', 'union', 'unit', 'unite', 'university', 'unless', 'until', 'up', 'upon', 'use', 'usual', 'value', 'various', 'very', 'video', 'view', 'village', 'visit', 'vote', 'wage', 'wait', 'walk', 'wall', 'want', 'war', 'warm', 'wash', 'waste', 'watch', 'water', 'way', 'we', 'wear', 'wednesday', 'wee', 'week', 'weigh', 'welcome', 'well', 'west', 'what', 'when', 'where', 'whether', 'which', 'while', 'white', 'who', 'whole', 'why', 'wide', 'wife', 'will', 'win', 'wind', 'window', 'wish', 'with', 'within', 'without', 'woman', 'wonder', 'wood', 'word', 'work', 'world', 'worry', 'worse', 'worth', 'would', 'write', 'wrong', 'year', 'yes', 'yesterday', 'yet', 'you', 'young']\n"
     ]
    }
   ],
   "source": [
    "# flatten the list structure, this uses the intertools module function chain \n",
    "word_list_flat = list(itertools.chain(*word_list)) \n",
    "\n",
    "print(word_list_flat)\n",
    "# great, we are getting there! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ab561ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the lists to be a string separated by a space \n",
    "words = \" \".join(word_list_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7751122d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a able about absolute accept account achieve across act active actual add address admit advertise affect afford after afternoon again against age agent ago agree air all allow almost along already alright also although always america amount and another answer any apart apparent appear apply appoint approach appropriate area argue arm around arrange art as ask associate assume at attend authority available aware away awful baby back bad bag balance ball bank bar base basis be bear beat beauty because become bed before begin behind believe benefit best bet between big bill birth bit black bloke blood blow blue board boat body book both bother bottle bottom box boy break brief brilliant bring britain brother budget build bus business busy but buy by cake call can car card care carry case cat catch cause cent centre certain chair chairman chance change chap character charge cheap check child choice choose Christ Christmas church city claim class clean clear client clock close closes clothe club coffee cold colleague collect college colour come comment commit committee common community company compare complete compute concern condition confer consider consult contact continue contract control converse cook copy corner correct cost could council count country county couple course court cover create cross cup current cut dad danger date day dead deal dear debate decide decision deep definite degree department depend describe design detail develop die difference difficult dinner direct discuss district divide do doctor document dog door double doubt down draw dress drink drive drop dry due during each early east easy eat economy educate effect egg eight either elect electric eleven else employ encourage end engine english enjoy enough enter environment equal especial europe even evening ever every evidence exact example except excuse exercise exist expect expense experience explain express extra eye face fact fair fall family far farm fast father favour feed feel few field fight figure file fill film final finance find fine finish fire first fish fit five flat floor fly follow food foot for force forget form fortune forward four france free friday friend from front full fun function fund further future game garden gas general germany get girl give glass go god good goodbye govern grand grant great green ground group grow guess guy hair half hall hand hang happen happy hard hate have he head health hear heart heat heavy hell help here high history hit hold holiday home honest hope horse hospital hot hour house how however hullo hundred husband idea identify if imagine important improve in include income increase indeed individual industry inform inside instead insure interest into introduce invest involve issue it item jesus job join judge jump just keep key kid kill kind king kitchen knock know labour lad lady land language large last late laugh law lay lead learn leave left leg less let letter level lie life light like likely limit line link list listen little live load local lock london long look lord lose lot love low luck lunch machine main major make man manage many mark market marry match matter may maybe mean meaning measure meet member mention middle might mile milk million mind minister minus minute miss mister moment monday money month more morning most mother motion move mrs much music must name nation nature near necessary need never new news next nice night nine no non none normal north not note notice now number obvious occasion odd of off offer office often okay old on once one only open operate opportunity oppose or order organize original other otherwise ought out over own pack page paint pair paper paragraph pardon parent park part particular party pass past pay pence pension people per percent perfect perhaps period person photograph pick picture piece place plan play please plus point police policy politic poor position positive possible post pound power practise prepare present press pressure presume pretty previous price print private probable problem proceed process produce product programme project proper propose protect provide public pull purpose push put quality quarter question quick quid quiet quite radio rail raise range rate rather read ready real realise really reason receive recent reckon recognize recommend record red reduce refer regard region relation remember report represent require research resource respect responsible rest result return rid right ring rise road role roll room round rule run safe sale same saturday save say scheme school science score scotland seat second secretary section secure see seem self sell send sense separate serious serve service set settle seven sex shall share she sheet shoe shoot shop short should show shut sick side sign similar simple since sing single sir sister sit site situate six size sleep slight slow small smoke so social society some son soon sorry sort sound south space speak special specific speed spell spend square staff stage stairs stand standard start state station stay step stick still stop story straight strategy street strike strong structure student study stuff stupid subject succeed such sudden suggest suit summer sun sunday supply support suppose sure surprise switch system table take talk tape tax tea teach team telephone television tell ten tend term terrible test than thank the then there therefore they thing think thirteen thirty this thou though thousand three through throw thursday tie time to today together tomorrow tonight too top total touch toward town trade traffic train transport travel treat tree trouble TRUE trust try tuesday turn twelve twenty two type under understand union unit unite university unless until up upon use usual value various very video view village visit vote wage wait walk wall want war warm wash waste watch water way we wear wednesday wee week weigh welcome well west what when where whether which while white who whole why wide wife will win wind window wish with within without woman wonder wood word work world worry worse worth would write wrong year yes yesterday yet you young\n"
     ]
    }
   ],
   "source": [
    "print(words) # happy days - we are ready to go "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dda6476",
   "metadata": {},
   "source": [
    "Now we are ready for the task! How many words: \n",
    "\n",
    "- Task 2: Start with \"y\"\n",
    "- Task 3: End with \"w\"\n",
    "- Task 4: Are exactly 3 letters long\n",
    "- Task 5: Have 8 letters or more\n",
    "- Task 6: contain only consonants\n",
    " \n",
    "Tasks 4, 5, and 6 are a bit more tricky. \n",
    "\n",
    "To really stretch yourself, consider using code to produce the answer to the above questions once you have a solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac54b203",
   "metadata": {},
   "source": [
    "<details><summary style='color:darkblue'>HINT 1: How to start breaking it down? CLICK HERE TO SEE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "    \n",
    "To address these problems you will need to use regular expressions. There is a helpful Python regular expression [cheat sheet here](https://www.dataquest.io/wp-content/uploads/2019/03/python-regular-expressions-cheat-sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6402887",
   "metadata": {},
   "source": [
    "<details><summary style='color:darkblue'>HINT 2: Useful functions. CLICK HERE TO SEE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "You do not need to manually count the string outputs, remember the `len()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453cd7ca",
   "metadata": {},
   "source": [
    "<details><summary style='color:darkblue'>HINT 3: How to use code to produce the answer?. CLICK HERE TO SEE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "We learned how to do string interpolation this week in the Python data types notebook (see section 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72da126",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbfe8f",
   "metadata": {},
   "source": [
    "#### Task 2 - 6 Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8bc25da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'yes', 'yesterday', 'yet', 'you', 'young']\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Start with \"y\"\n",
    "\n",
    "print(re.findall(r'\\b[y]\\w+', words)) \n",
    "\n",
    "## the r prefix before the pattern string creates a raw string, which we need for the following regular expression  \n",
    "## \\b maching the boundary at the start or end of a word (a non-word character)\n",
    "## [] contain a set of characters to match \n",
    "## y is our alphanumeric character of interest to match \n",
    "## \\w matches alphanumeric characters \n",
    "## + greedily matches the expression to its left 1 or more times\n",
    "\n",
    "## remove or edit one or more of these regex components to get a better understanding of how this works "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b514de",
   "metadata": {},
   "source": [
    "There are 6 words that start with 'y'. We could also write this answer using code! For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0e0574d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There are 6 words that start with 'y' in the data\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we need to create an object with our list of words that match out criteria \n",
    "task2 = re.findall(r'\\b[y]\\w+', words)\n",
    "\n",
    "# then we can use an f-string \n",
    "f\"There are {len(task2)} words that start with 'y' in the data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58df51fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 words that start with 'y' in the data\n"
     ]
    }
   ],
   "source": [
    "## if you wrap your fstring in a print function, it will print without the quotation marks \n",
    "print(f\"There are {len(task2)} words that start with 'y' in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea053348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 words that start with 'y' in the data\n"
     ]
    }
   ],
   "source": [
    "## or we can use print without the f-string, which is slightly less elegant \n",
    "print(\"There are\", len(task2), \"words that start with 'y' in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f5928a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allow', 'blow', 'draw', 'few', 'follow', 'grow', 'how', 'know', 'law', 'low', 'new', 'now', 'show', 'slow', 'throw', 'tomorrow', 'view', 'window']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# Task 3: End with \"w\"\n",
    "print(re.findall(r'\\w+[w]\\b', words))\n",
    "\n",
    "## the r prefix before the pattern string creates a raw string, which we need for the following regular expression  \n",
    "## \\w matches alphanumeric characters\n",
    "## + greedily matches the expression to its left 1 or more times\n",
    "## [] contain a set of characters to match \n",
    "## w is our alphanumeric character of interest to match \n",
    "## \\b maching the boundary at the start or end of a word (a non-word character)\n",
    "\n",
    "print(len(re.findall(r'\\w+[w]\\b', words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2da9325b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 words that end with 'w' in the data\n"
     ]
    }
   ],
   "source": [
    "## and now to answer the question with code \n",
    "task3 = re.findall(r'\\w+[w]\\b', words)\n",
    "\n",
    "print(f\"There are {len(task3)} words that end with 'w' in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cfb668b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 4: Are exactly 3 letters long\n",
    "task4 = re.findall(r'(\\b\\w{3}\\b)', words)\n",
    "\n",
    "## in regex {} matches exactly exact input number of copies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5464b8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 110 words with exactly 3 letters in the data\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(task4)} words with exactly 3 letters in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fc35d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Have 8 letters or more\n",
    "task_5 = re.findall(r'(\\b\\w{8,12}\\b)', words)\n",
    "\n",
    "## {} matches exactly exact input number of copies from number, to number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44714622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 words that have 8 letters or more in the data\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(task_5)} words that have 8 letters or more in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5ca0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: contain only consonants\n",
    "\n",
    "## one approach is to say NOT vowels \n",
    "task6_0 = re.findall(r'\\b[^aeiou\\W]+\\b', words, flags = re.IGNORECASE)\n",
    "\n",
    "## within a set [] ^ means not so adding ^ at the front excludes any character in the set\n",
    "## + matches previous token 1+ times \n",
    "## \\W is a meta escape matching any non-word character (this removes the empty spaces)\n",
    "### delete in the code above and see what happens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df95c8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 words which contain only consonants in the data\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(task6_0)} words which contain only consonants in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffb2d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "## another approach is to specify only consonants more manually \n",
    "task6_1 = re.findall(r'\\b[b-df-hj-np-tv-z]+\\b', words, flags = re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e850ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 words which contain only consonants in the data\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(task6_1)} words which contain only consonants in the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704295d",
   "metadata": {},
   "source": [
    "## 2. Categorical data (and Boolean and Numeric and Missing) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb18520",
   "metadata": {},
   "source": [
    "For this section, there is yet again a data set available in R that we will be using. This time the data comes from the `forcats` package. `forcats::gss_cat` is a sample of data from the General Social Survey, which is a long-running US survey conducted by the independent research organization NORC at the University of Chicago. As the survey has thousands of questions, the `gss_cat` data contains a small subset. \n",
    "\n",
    "Since this data set is provided by an R package, you can get more information about the variables **in R** with `?gss_cat`. \n",
    "\n",
    "As above, to read in the data we will be using our new friend, the the `pd.read_csv('file.csv')` function from the `pandas` package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91f67f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>marital</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>rincome</th>\n",
       "      <th>partyid</th>\n",
       "      <th>relig</th>\n",
       "      <th>tvhours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Never married</td>\n",
       "      <td>26.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$8000 to 9999</td>\n",
       "      <td>Ind,near rep</td>\n",
       "      <td>Protestant</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>48.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$8000 to 9999</td>\n",
       "      <td>Not str republican</td>\n",
       "      <td>Protestant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>67.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Protestant</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>Never married</td>\n",
       "      <td>39.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Ind,near rep</td>\n",
       "      <td>Orthodox-christian</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>25.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not str democrat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>2014</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>89.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not str republican</td>\n",
       "      <td>Protestant</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21479</th>\n",
       "      <td>2014</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>56.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$25000 or more</td>\n",
       "      <td>Independent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21480</th>\n",
       "      <td>2014</td>\n",
       "      <td>Never married</td>\n",
       "      <td>24.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$10000 - 14999</td>\n",
       "      <td>Ind,near dem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21481</th>\n",
       "      <td>2014</td>\n",
       "      <td>Never married</td>\n",
       "      <td>27.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$25000 or more</td>\n",
       "      <td>Not str democrat</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21482</th>\n",
       "      <td>2014</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>71.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$20000 - 24999</td>\n",
       "      <td>Ind,near rep</td>\n",
       "      <td>Protestant</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21483 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year        marital   age   race         rincome             partyid  \\\n",
       "0      2000  Never married  26.0  White   $8000 to 9999        Ind,near rep   \n",
       "1      2000       Divorced  48.0  White   $8000 to 9999  Not str republican   \n",
       "2      2000        Widowed  67.0  White  Not applicable         Independent   \n",
       "3      2000  Never married  39.0  White  Not applicable        Ind,near rep   \n",
       "4      2000       Divorced  25.0  White  Not applicable    Not str democrat   \n",
       "...     ...            ...   ...    ...             ...                 ...   \n",
       "21478  2014        Widowed  89.0  White  Not applicable  Not str republican   \n",
       "21479  2014       Divorced  56.0  White  $25000 or more         Independent   \n",
       "21480  2014  Never married  24.0  White  $10000 - 14999        Ind,near dem   \n",
       "21481  2014  Never married  27.0  White  $25000 or more    Not str democrat   \n",
       "21482  2014        Widowed  71.0  White  $20000 - 24999        Ind,near rep   \n",
       "\n",
       "                    relig  tvhours  \n",
       "0              Protestant     12.0  \n",
       "1              Protestant      NaN  \n",
       "2              Protestant      2.0  \n",
       "3      Orthodox-christian      4.0  \n",
       "4                     NaN      1.0  \n",
       "...                   ...      ...  \n",
       "21478          Protestant      3.0  \n",
       "21479                 NaN      4.0  \n",
       "21480                 NaN      4.0  \n",
       "21481            Catholic      NaN  \n",
       "21482          Protestant      2.0  \n",
       "\n",
       "[21483 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "## my data is in a folder called data. If you do not have the same set up, update the file path accordingly \n",
    "gss_cat = pd.read_csv('../data/gss_cat.csv')\n",
    "\n",
    "gss_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10f9df1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21483 entries, 0 to 21482\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   year     21483 non-null  int64  \n",
      " 1   marital  21483 non-null  object \n",
      " 2   age      21407 non-null  float64\n",
      " 3   race     21483 non-null  object \n",
      " 4   rincome  21483 non-null  object \n",
      " 5   partyid  21483 non-null  object \n",
      " 6   relig    17960 non-null  object \n",
      " 7   tvhours  11337 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "## we will learn more about data frames next week but one function to get a summary of what a data frame contains is data.info()\n",
    "## data.info() is similiar to glimpse() in R \n",
    "gss_cat.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6629b9",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "What data types are the different variables in `gss_cat`? If there is categoical data, should it be nominal or ordinal? What are the categories of the categorical data? Should or could any of the variable be represented differently in terms of data type?\n",
    "\n",
    "Go through the data set one column at a time answering the above questions for each of the 8 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da9c5c",
   "metadata": {},
   "source": [
    "<details><summary style='color:darkblue'>HINT 1: Some new functions! CLICK HERE TO SEE THE ANSWER.</summary>\n",
    "\n",
    "This task asks for you to do something we are familiar with from last week - thinking about data types - but to do so you need to use some code we have not learned about yet for working with dataframes. To select a single column, use square brackets `[]` with the column name of the column of interest as a character string - e.g., `dataframe[\"column\"]`. We will discuss this more next week, for those interested, the returned object is a `pandas Series` (which we used some in the Python Data Types Notebook). \n",
    "    \n",
    "Then you can use the `data.head()` function to see the first few rows of data as well as the data type.\n",
    "    \n",
    "You can also use `data.decribe()` to get a summary of the variable. To get more higher level information you can use `data.info()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89bcd39",
   "metadata": {},
   "source": [
    "<details><summary style='color:darkblue'>HINT 2: A new data type (gasp there's more!). CLICK HERE TO SEE THE ANSWER.</summary>\n",
    "\n",
    "You will notice that some variables/columns are something called type `object`... but what does this mean?? In `pandas` a `object dtype` represents text or mixed numeric and non-numeric values. An `object` is a string in `pandas` so it performs a string operation instead of a mathematical one. Thus, if you want a variable to be treated as categorical (`dtype category`) you need to explicitly cast it as such. The simplest way to convert a column to a categorical type is to use `astype('category')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8010c",
   "metadata": {},
   "source": [
    "#### Task 7 Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0c3a7",
   "metadata": {},
   "source": [
    "#### 7.1 year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28e84912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2000\n",
      "1    2000\n",
      "2    2000\n",
      "3    2000\n",
      "4    2000\n",
      "Name: year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"year\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "157cb5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    21483.000000\n",
      "mean      2006.501978\n",
      "std          4.451994\n",
      "min       2000.000000\n",
      "25%       2002.000000\n",
      "50%       2006.000000\n",
      "75%       2010.000000\n",
      "max       2014.000000\n",
      "Name: year, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"year\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06eab6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 21483 entries, 0 to 21482\n",
      "Series name: year\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "21483 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 168.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"year\"].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cd42a",
   "metadata": {},
   "source": [
    "`Year` is an integer (specifically `int64`) ranging from 2000 to 2014, but may be suited as an ordered factor depending on the use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f01f7",
   "metadata": {},
   "source": [
    "#### 7.2 marital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aaac79f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Never married\n",
      "1         Divorced\n",
      "2          Widowed\n",
      "3    Never married\n",
      "4         Divorced\n",
      "Name: marital, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"marital\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b450016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       21483\n",
      "unique          6\n",
      "top       Married\n",
      "freq        10117\n",
      "Name: marital, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"marital\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36456dae",
   "metadata": {},
   "source": [
    "`Martial` is an currently an `object` data type, meaning it is being treated as a string, with 6 unique responses (eventually categories). It would make most sense to be a nominal categorical variable. Though using an ordinal category and having \"Never married\" sorted as the first level then \"Married\" followed by \"Separated\", \"Divorced\", \"Widowed\", and \"No answer\" would make sense for some data presentations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65212fc0",
   "metadata": {},
   "source": [
    "#### 7.3 age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ae2da58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    26.0\n",
      "1    48.0\n",
      "2    67.0\n",
      "3    39.0\n",
      "4    25.0\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"age\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "613328d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    21407.000000\n",
      "mean        47.180081\n",
      "std         17.287500\n",
      "min         18.000000\n",
      "25%         33.000000\n",
      "50%         46.000000\n",
      "75%         59.000000\n",
      "max         89.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"age\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83eeb94",
   "metadata": {},
   "source": [
    "`Age` is a float (specifically `float64`) ranging from 18 to 89. Depending on the analytic use case, `age` could also work as an oridnal categorical variable with user-determined-determined age brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7c7be",
   "metadata": {},
   "source": [
    "#### 7.4 race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d99f5fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    White\n",
      "1    White\n",
      "2    White\n",
      "3    White\n",
      "4    White\n",
      "Name: race, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"race\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f210bbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     21483\n",
      "unique        3\n",
      "top       White\n",
      "freq      16395\n",
      "Name: race, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"race\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e411b4dd",
   "metadata": {},
   "source": [
    "`Race` is an an `object` data type with 3 unique responses. It makes sense to cast `race` as a nominal categorical variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7bb22",
   "metadata": {},
   "source": [
    "#### 7.5 rincome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66f9e706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     $8000 to 9999\n",
      "1     $8000 to 9999\n",
      "2    Not applicable\n",
      "3    Not applicable\n",
      "4    Not applicable\n",
      "Name: rincome, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"rincome\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80792212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count              21483\n",
      "unique                16\n",
      "top       $25000 or more\n",
      "freq                7363\n",
      "Name: rincome, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"rincome\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae2713b",
   "metadata": {},
   "source": [
    "`rincome` is an `object` data type with 16 unique responses. This variable would likely be most useful as categorical. Depending on the amount of detail needed for analysis of this variable, it would make sense to collapse some categories together and make the variable an ordered categorical. It could also be useful to convert to a string in some instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc0da2",
   "metadata": {},
   "source": [
    "#### 7.6 partyid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a189f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Ind,near rep\n",
      "1    Not str republican\n",
      "2           Independent\n",
      "3          Ind,near rep\n",
      "4      Not str democrat\n",
      "Name: partyid, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"partyid\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad013bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count           21483\n",
      "unique             10\n",
      "top       Independent\n",
      "freq             4119\n",
      "Name: partyid, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"partyid\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fece6c",
   "metadata": {},
   "source": [
    "`partyid` is an `object` data type with 10 unique responses. It would make sense to cast this varibale as categorical. In some use cases it may be useful to make this an ordinal categorical variable, ordering the categories according to how they fall on the political spectrum. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac568893",
   "metadata": {},
   "source": [
    "#### 7.7 relig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c0ca4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            Protestant\n",
      "1            Protestant\n",
      "2            Protestant\n",
      "3    Orthodox-christian\n",
      "4                   NaN\n",
      "Name: relig, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"relig\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23f11eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count          17960\n",
      "unique            14\n",
      "top       Protestant\n",
      "freq           10846\n",
      "Name: relig, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"relig\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36be66",
   "metadata": {},
   "source": [
    "`relig` is an `object` data type 10 unique responses. It would like be useful to cast `relig` as a nominal categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb5d04",
   "metadata": {},
   "source": [
    "#### 7.8 tvhours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca2cf9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12.0\n",
      "1     NaN\n",
      "2     2.0\n",
      "3     4.0\n",
      "4     1.0\n",
      "Name: tvhours, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"tvhours\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7d3957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    11337.000000\n",
      "mean         2.980771\n",
      "std          2.587151\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max         24.000000\n",
      "Name: tvhours, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(gss_cat[\"tvhours\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153731e4",
   "metadata": {},
   "source": [
    "`tvhours` is a float (specifically `float64`) from 0 to 24. Depending on the analytic use case, `tvhours` could also work as an ordinal categorical variable with user-determined-determined category levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f51d3e7",
   "metadata": {},
   "source": [
    "## Task 8 \n",
    "\n",
    "Make `age` a factor. When modifying an object by changing values or the data type, it is good practice to create a new object with a meaningfully modified name rather than over-write the original one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ad0767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's take out age as a pandas Series \n",
    "age = gss_cat[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed2a932d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0468e0a1",
   "metadata": {},
   "source": [
    "#### Task 8 Solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d8aaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_f = age.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41e038",
   "metadata": {},
   "source": [
    "After changing an object, it is good practice to check that your code made the expected changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32010f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26.0\n",
       "1    48.0\n",
       "2    67.0\n",
       "3    39.0\n",
       "4    25.0\n",
       "Name: age, dtype: category\n",
       "Categories (72, float64): [18.0, 19.0, 20.0, 21.0, ..., 86.0, 87.0, 88.0, 89.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_f.head() # all good "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be716d",
   "metadata": {},
   "source": [
    "### Task 8 Advanced \n",
    "\n",
    "It is a bit more advanced to from here make `age` an ordinal categorical data type with 5 levels: 18-25, 26-44, 45-64, 65-74, 75+. To do so, we need to use `pandas.cut()` to sort out data values into bins. \n",
    "\n",
    "**Before looking at the solution, challenge yourself to think about the logical steps needed to solve this problem. Write them down and see how they match up to the solution provided.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e2eae",
   "metadata": {},
   "source": [
    "##### Your answer to the logical steps \n",
    "\n",
    "1. ....\n",
    "\n",
    "\n",
    "2. ....\n",
    "\n",
    "\n",
    "3. ....\n",
    "\n",
    "\n",
    "4. ....\n",
    "\n",
    "\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998d04a",
   "metadata": {},
   "source": [
    "As we have not learned about this function yet, I will show you the solution and ask for you to try and figure out how it works. Modify some of the code to see what happens. Do not worry, you cannot break your computer (unless you throw it perhaps)! If you have any errors you cannot figure out, ask one of the teaching team for help during the tutorial or post on the discussion boards afterwards. \n",
    "\n",
    "Before making any changes to our variable, it is good practice to check if there are any missing values lurking in the shadows trying to ruin our day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25f20362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_f.isna().values.any()\n",
    "\n",
    "## try to run the above about without .values.any() to see why we need it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "950aa77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next we can use sum to see how many there are \n",
    "## becuase is.na() returns Boolean values and True is truthy, we can use sum... understanding data types is so useful! \n",
    "\n",
    "age_f.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eea256",
   "metadata": {},
   "source": [
    "So we do indeed have some missing values (76 to be exact), which we will keep in mind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9fa5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_groups = pd.cut(\n",
    "    age_f,\n",
    "    bins = [-np.inf, 25, 44, 64, 74, np.inf],\n",
    "    labels = [\"18-25\", \"26-44\", \"45-64\", \"65-74\", \"75+\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1afe78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26-44\n",
       "1    45-64\n",
       "2    65-74\n",
       "3    26-44\n",
       "4    18-25\n",
       "Name: age, dtype: category\n",
       "Categories (5, object): ['18-25' < '26-44' < '45-64' < '65-74' < '75+']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_groups.head() # looking good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0e37064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['18-25', '26-44', '45-64', '65-74', '75+'], dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_groups.cat.categories # celebration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1974965e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# and look at that, pandas.cut() made it ordered for us too! \n",
    "## this is because the default behavior of the argument ordered is True\n",
    "print(age_groups.cat.ordered) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a429fe55",
   "metadata": {},
   "source": [
    "Reading documentation is a skill that you will develop over time with practice. Try and read the documentation for the cut function from pandas to see what you and learn. Ask a member of the teaching team during the tutorial or post on the discussion boards if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65e4e13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cut in module pandas.core.reshape.tile:\n",
      "\n",
      "cut(x, bins, right: 'bool' = True, labels=None, retbins: 'bool' = False, precision: 'int' = 3, include_lowest: 'bool' = False, duplicates: 'str' = 'raise', ordered: 'bool' = True)\n",
      "    Bin values into discrete intervals.\n",
      "\n",
      "    Use `cut` when you need to segment and sort data values into bins. This\n",
      "    function is also useful for going from a continuous variable to a\n",
      "    categorical variable. For example, `cut` could convert ages to groups of\n",
      "    age ranges. Supports binning into an equal number of bins, or a\n",
      "    pre-specified array of bins.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array-like\n",
      "        The input array to be binned. Must be 1-dimensional.\n",
      "    bins : int, sequence of scalars, or IntervalIndex\n",
      "        The criteria to bin by.\n",
      "\n",
      "        * int : Defines the number of equal-width bins in the range of `x`. The\n",
      "          range of `x` is extended by .1% on each side to include the minimum\n",
      "          and maximum values of `x`.\n",
      "        * sequence of scalars : Defines the bin edges allowing for non-uniform\n",
      "          width. No extension of the range of `x` is done.\n",
      "        * IntervalIndex : Defines the exact bins to be used. Note that\n",
      "          IntervalIndex for `bins` must be non-overlapping.\n",
      "\n",
      "    right : bool, default True\n",
      "        Indicates whether `bins` includes the rightmost edge or not. If\n",
      "        ``right == True`` (the default), then the `bins` ``[1, 2, 3, 4]``\n",
      "        indicate (1,2], (2,3], (3,4]. This argument is ignored when\n",
      "        `bins` is an IntervalIndex.\n",
      "    labels : array or False, default None\n",
      "        Specifies the labels for the returned bins. Must be the same length as\n",
      "        the resulting bins. If False, returns only integer indicators of the\n",
      "        bins. This affects the type of the output container (see below).\n",
      "        This argument is ignored when `bins` is an IntervalIndex. If True,\n",
      "        raises an error. When `ordered=False`, labels must be provided.\n",
      "    retbins : bool, default False\n",
      "        Whether to return the bins or not. Useful when bins is provided\n",
      "        as a scalar.\n",
      "    precision : int, default 3\n",
      "        The precision at which to store and display the bins labels.\n",
      "    include_lowest : bool, default False\n",
      "        Whether the first interval should be left-inclusive or not.\n",
      "    duplicates : {default 'raise', 'drop'}, optional\n",
      "        If bin edges are not unique, raise ValueError or drop non-uniques.\n",
      "    ordered : bool, default True\n",
      "        Whether the labels are ordered or not. Applies to returned types\n",
      "        Categorical and Series (with Categorical dtype). If True,\n",
      "        the resulting categorical will be ordered. If False, the resulting\n",
      "        categorical will be unordered (labels must be provided).\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : Categorical, Series, or ndarray\n",
      "        An array-like object representing the respective bin for each value\n",
      "        of `x`. The type depends on the value of `labels`.\n",
      "\n",
      "        * None (default) : returns a Series for Series `x` or a\n",
      "          Categorical for all other inputs. The values stored within\n",
      "          are Interval dtype.\n",
      "\n",
      "        * sequence of scalars : returns a Series for Series `x` or a\n",
      "          Categorical for all other inputs. The values stored within\n",
      "          are whatever the type in the sequence is.\n",
      "\n",
      "        * False : returns an ndarray of integers.\n",
      "\n",
      "    bins : numpy.ndarray or IntervalIndex.\n",
      "        The computed or specified bins. Only returned when `retbins=True`.\n",
      "        For scalar or sequence `bins`, this is an ndarray with the computed\n",
      "        bins. If set `duplicates=drop`, `bins` will drop non-unique bin. For\n",
      "        an IntervalIndex `bins`, this is equal to `bins`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    qcut : Discretize variable into equal-sized buckets based on rank\n",
      "        or based on sample quantiles.\n",
      "    Categorical : Array type for storing data that come from a\n",
      "        fixed set of values.\n",
      "    Series : One-dimensional array with axis labels (including time series).\n",
      "    IntervalIndex : Immutable Index implementing an ordered, sliceable set.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Any NA values will be NA in the result. Out of bounds values will be NA in\n",
      "    the resulting Series or Categorical object.\n",
      "\n",
      "    Reference :ref:`the user guide <reshaping.tile.cut>` for more examples.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Discretize into three equal-sized bins.\n",
      "\n",
      "    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3)\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    [(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], ...\n",
      "    Categories (3, interval[float64, right]): [(0.994, 3.0] < (3.0, 5.0] ...\n",
      "\n",
      "    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3, retbins=True)\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    ([(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], ...\n",
      "    Categories (3, interval[float64, right]): [(0.994, 3.0] < (3.0, 5.0] ...\n",
      "    array([0.994, 3.   , 5.   , 7.   ]))\n",
      "\n",
      "    Discovers the same bins, but assign them specific labels. Notice that\n",
      "    the returned Categorical's categories are `labels` and is ordered.\n",
      "\n",
      "    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]),\n",
      "    ...        3, labels=[\"bad\", \"medium\", \"good\"])\n",
      "    ['bad', 'good', 'medium', 'medium', 'good', 'bad']\n",
      "    Categories (3, object): ['bad' < 'medium' < 'good']\n",
      "\n",
      "    ``ordered=False`` will result in unordered categories when labels are passed.\n",
      "    This parameter can be used to allow non-unique labels:\n",
      "\n",
      "    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,\n",
      "    ...        labels=[\"B\", \"A\", \"B\"], ordered=False)\n",
      "    ['B', 'B', 'A', 'A', 'B', 'B']\n",
      "    Categories (2, object): ['A', 'B']\n",
      "\n",
      "    ``labels=False`` implies you just want the bins back.\n",
      "\n",
      "    >>> pd.cut([0, 1, 1, 2], bins=4, labels=False)\n",
      "    array([0, 1, 1, 3])\n",
      "\n",
      "    Passing a Series as an input returns a Series with categorical dtype:\n",
      "\n",
      "    >>> s = pd.Series(np.array([2, 4, 6, 8, 10]),\n",
      "    ...               index=['a', 'b', 'c', 'd', 'e'])\n",
      "    >>> pd.cut(s, 3)\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    a    (1.992, 4.667]\n",
      "    b    (1.992, 4.667]\n",
      "    c    (4.667, 7.333]\n",
      "    d     (7.333, 10.0]\n",
      "    e     (7.333, 10.0]\n",
      "    dtype: category\n",
      "    Categories (3, interval[float64, right]): [(1.992, 4.667] < (4.667, ...\n",
      "\n",
      "    Passing a Series as an input returns a Series with mapping value.\n",
      "    It is used to map numerically to intervals based on bins.\n",
      "\n",
      "    >>> s = pd.Series(np.array([2, 4, 6, 8, 10]),\n",
      "    ...               index=['a', 'b', 'c', 'd', 'e'])\n",
      "    >>> pd.cut(s, [0, 2, 4, 6, 8, 10], labels=False, retbins=True, right=False)\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    (a    1.0\n",
      "     b    2.0\n",
      "     c    3.0\n",
      "     d    4.0\n",
      "     e    NaN\n",
      "     dtype: float64,\n",
      "     array([ 0,  2,  4,  6,  8, 10]))\n",
      "\n",
      "    Use `drop` optional when bins is not unique\n",
      "\n",
      "    >>> pd.cut(s, [0, 2, 4, 6, 10, 10], labels=False, retbins=True,\n",
      "    ...        right=False, duplicates='drop')\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    (a    1.0\n",
      "     b    2.0\n",
      "     c    3.0\n",
      "     d    3.0\n",
      "     e    NaN\n",
      "     dtype: float64,\n",
      "     array([ 0,  2,  4,  6, 10]))\n",
      "\n",
      "    Passing an IntervalIndex for `bins` results in those categories exactly.\n",
      "    Notice that values not covered by the IntervalIndex are set to NaN. 0\n",
      "    is to the left of the first bin (which is closed on the right), and 1.5\n",
      "    falls between two bins.\n",
      "\n",
      "    >>> bins = pd.IntervalIndex.from_tuples([(0, 1), (2, 3), (4, 5)])\n",
      "    >>> pd.cut([0, 0.5, 1.5, 2.5, 4.5], bins)\n",
      "    [NaN, (0.0, 1.0], NaN, (2.0, 3.0], (4.0, 5.0]]\n",
      "    Categories (3, interval[int64, right]): [(0, 1] < (2, 3] < (4, 5]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at the documentation for more info \n",
    "help(pd.cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e798f46",
   "metadata": {},
   "source": [
    "### Task 9 \n",
    "\n",
    "How could you collapse `rincome` into a small set of categories (e.g., `\"Unknown\"`, `\"less than $5000\"`, `\"$5000 to $9999\"`, `\"$10000 or more\"`)?\n",
    "\n",
    "Look at some summaries of the object and think about some of the challenges that you need to overcome to complete the task. Write down the steps you would need to take in plain language, regardless of if you know how to do it in code. Understanding **what** you need to do is just an important, if not more so, than **how** you will do it (i.e., in code).\n",
    "\n",
    "You can also look back at your solution to Task 7 above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9472c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count              21483\n",
      "unique                16\n",
      "top       $25000 or more\n",
      "freq                7363\n",
      "Name: rincome, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# first let's take out rincome as a pandas Series \n",
    "rincome = gss_cat[\"rincome\"]\n",
    "\n",
    "print(rincome.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a80be689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     $8000 to 9999\n",
      "1     $8000 to 9999\n",
      "2    Not applicable\n",
      "3    Not applicable\n",
      "4    Not applicable\n",
      "Name: rincome, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(rincome.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2aba0099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$8000 to 9999' 'Not applicable' '$20000 - 24999' '$25000 or more'\n",
      " '$7000 to 7999' '$10000 - 14999' 'Refused' '$15000 - 19999'\n",
      " '$3000 to 3999' '$5000 to 5999' \"Don't know\" '$1000 to 2999' 'Lt $1000'\n",
      " 'No answer' '$6000 to 6999' '$4000 to 4999']\n"
     ]
    }
   ],
   "source": [
    "print(rincome.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae133e9",
   "metadata": {},
   "source": [
    "##### Your answer to the logical steps \n",
    "\n",
    "1. ....\n",
    "\n",
    "\n",
    "2. ....\n",
    "\n",
    "\n",
    "3. ....\n",
    "\n",
    "\n",
    "4. ....\n",
    "\n",
    "\n",
    "....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25641cf2",
   "metadata": {},
   "source": [
    "#### Task 9 Solution \n",
    "\n",
    "\n",
    "`rincome` is currently an object data type. It is also quite messy. The unique categories do not have consistent naming conventions (some say \"to\" and other use \"-\") so we need fix that. Then, we will want to group all of the non-responses into one category and the responses into 3 categories. We will then want to cast this as an ordered categorical data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b120ab1",
   "metadata": {},
   "source": [
    "### Advanced bonus task (Task 9) \n",
    "\n",
    "The advanced bonus task, should you choose to accept it, is to attempt your solution to Task 9 in code! See how far you can get! Have a look at the solutions document for a worked solution to this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df131f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd29ce",
   "metadata": {},
   "source": [
    "#### Advanced bonus task Solution (Task 9) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433616a3",
   "metadata": {},
   "source": [
    "In order to complete this task we can use python data structures to our advantage (we will learn more about this next week). I have used a data structure called dictionaries (which store `key:value` pairs and are denoted with `{}`) and manipulated the variable within the dataframe, rather than subsetting it. I also used the `map()` function to iterate over the column and stored our solution as a new column called `rincome_cat`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06b82b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$8000 to 9999', 'Not applicable', '$20000 to 24999',\n",
       "       '$25000 or more', '$7000 to 7999', '$10000 to 14999', 'Refused',\n",
       "       '$15000 to 19999', '$3000 to 3999', '$5000 to 5999', \"Don't know\",\n",
       "       '$1000 to 2999', 'Lt $1000', 'No answer', '$6000 to 6999',\n",
       "       '$4000 to 4999'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this step is not necessary as we could have just used the label as it is in the dictionary created below\n",
    "## but I have shown in just in case you tried something similiar \n",
    "rincome_name = rincome.replace({'$20000 - 24999' : '$20000 to 24999', \n",
    "                                '$15000 - 19999' : '$15000 to 19999',\n",
    "                                \"$10000 - 14999\" : '$10000 to 14999'})\n",
    "\n",
    "# check it worked as expected\n",
    "rincome_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c906cc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>marital</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>rincome</th>\n",
       "      <th>partyid</th>\n",
       "      <th>relig</th>\n",
       "      <th>tvhours</th>\n",
       "      <th>rincome_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21483.000000</td>\n",
       "      <td>21483</td>\n",
       "      <td>21407.000000</td>\n",
       "      <td>21483</td>\n",
       "      <td>21483</td>\n",
       "      <td>21483</td>\n",
       "      <td>17960</td>\n",
       "      <td>11337.000000</td>\n",
       "      <td>21483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>$25000 or more</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Protestant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$10000 or more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16395</td>\n",
       "      <td>7363</td>\n",
       "      <td>4119</td>\n",
       "      <td>10846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2006.501978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.180081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.980771</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.451994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.287500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.587151</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2006.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                year  marital           age   race         rincome  \\\n",
       "count   21483.000000    21483  21407.000000  21483           21483   \n",
       "unique           NaN        6           NaN      3              16   \n",
       "top              NaN  Married           NaN  White  $25000 or more   \n",
       "freq             NaN    10117           NaN  16395            7363   \n",
       "mean     2006.501978      NaN     47.180081    NaN             NaN   \n",
       "std         4.451994      NaN     17.287500    NaN             NaN   \n",
       "min      2000.000000      NaN     18.000000    NaN             NaN   \n",
       "25%      2002.000000      NaN     33.000000    NaN             NaN   \n",
       "50%      2006.000000      NaN     46.000000    NaN             NaN   \n",
       "75%      2010.000000      NaN     59.000000    NaN             NaN   \n",
       "max      2014.000000      NaN     89.000000    NaN             NaN   \n",
       "\n",
       "            partyid       relig       tvhours     rincome_cat  \n",
       "count         21483       17960  11337.000000           21483  \n",
       "unique           10          14           NaN               4  \n",
       "top     Independent  Protestant           NaN  $10000 or more  \n",
       "freq           4119       10846           NaN           10862  \n",
       "mean            NaN         NaN      2.980771             NaN  \n",
       "std             NaN         NaN      2.587151             NaN  \n",
       "min             NaN         NaN      0.000000             NaN  \n",
       "25%             NaN         NaN      1.000000             NaN  \n",
       "50%             NaN         NaN      2.000000             NaN  \n",
       "75%             NaN         NaN      4.000000             NaN  \n",
       "max             NaN         NaN     24.000000             NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary with our desired names \n",
    "map_dict = {\"No answer\" : \"Unknown\", \n",
    "            \"Don't know\" : \"Unknown\",  \n",
    "            \"Refused\" : \"Unknown\", \n",
    "            \"Not applicable\" : \"Unknown\",\n",
    "            \"Lt $1000\" : \"Less than $5000\", \n",
    "            \"$1000 to 2999\" : \"Less than $5000\", \n",
    "            \"$3000 to 3999\" : \"Less than $5000\", \n",
    "            \"$4000 to 4999\" : \"Less than $5000\",\n",
    "            \"$5000 to 5999\" : \"$5000 to $9999\", \n",
    "            \"$6000 to 6999\" : \"$5000 to $9999\", \n",
    "            \"$7000 to 7999\" : \"$5000 to $9999\", \n",
    "            \"$8000 to 9999\" : \"$5000 to $9999\", \n",
    "            \"$10000 - 14999\" : \"$10000 or more\", \n",
    "            \"$15000 - 19999\" : \"$10000 or more\", \n",
    "            \"$20000 - 24999\" : \"$10000 or more\", \n",
    "            \"$25000 or more\" : \"$10000 or more\"}\n",
    "\n",
    "# create new column, interate over rincome with the dictionary created above, and change type to category \n",
    "gss_cat[\"rincome_cat\"] = gss_cat[\"rincome\"].map(map_dict).astype(\"category\")\n",
    "\n",
    "gss_cat.describe(include = 'all') # excellent, looks like we have 4 categories in rincome_cat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0992fce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$5000 to $9999', 'Unknown', '$10000 or more', 'Less than $5000']\n",
       "Categories (4, object): ['$10000 or more', '$5000 to $9999', 'Less than $5000', 'Unknown']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gss_cat[\"rincome_cat\"].unique() \n",
    "## looking good but we also now want it to be an ordered categorical variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "571f5390",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gss_cat[\"rincome_cat\"] = gss_cat[\"rincome_cat\"].cat.as_ordered() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76661e59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$5000 to $9999', 'Unknown', '$10000 or more', 'Less than $5000']\n",
       "Categories (4, object): ['$10000 or more' < '$5000 to $9999' < 'Less than $5000' < 'Unknown']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gss_cat[\"rincome_cat\"].unique() ## happy days "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d10ad",
   "metadata": {},
   "source": [
    "## 3. Date and time data (and string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38954874",
   "metadata": {},
   "source": [
    "### Task 10 \n",
    "\n",
    "Create an object showing the date 140 days from now and print the output nicely formatted (`\"month day, year at hour minute\"`) using `strftime()`. Then create an object with the date 2 years from now and similarly print the output nicely formatted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd50c25",
   "metadata": {},
   "source": [
    "<details><summary style='color:darkblue'>HINT 1: How to start breaking it down? CLICK HERE TO SEE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "    \n",
    "`timedelta` instances allow for arithmetic, but only at the level of days, hours, minutes, or seconds. To add or subtract intervals larger than a day, such as a month or a year we use `relativedelta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e262d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a470c",
   "metadata": {},
   "source": [
    "#### Task 10 Solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d65e3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 20, 2024 at 13:31\n"
     ]
    }
   ],
   "source": [
    "## 140 days from now \n",
    "days140 = dt.datetime.now() + dt.timedelta(days =+ 140)  \n",
    "# the after the + is not strictly needed, but is to explicitly state that I want a positive integer \n",
    "## change to a - to see what happens \n",
    "\n",
    "print(days140.strftime(\"%B %d, %Y at %H:%M\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdae05ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May 03, 2026 at 13:31\n"
     ]
    }
   ],
   "source": [
    "## 2 years from now \n",
    "years2 = dt.datetime.now() + relativedelta.relativedelta(years = 2)\n",
    "\n",
    "print(years2.strftime(\"%B %d, %Y at %H:%M\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93e2fd",
   "metadata": {},
   "source": [
    "## Task 11 \n",
    "\n",
    "This is a big one, so I have separated the task into different parts. By the end, you will have made a countdown clock to your birthday! (how cool!)\n",
    "\n",
    "We will start by making a countdown clock until the annual Fringe Festival in Edinburgh in August. The festival starts on 2 August 2024 at 13:35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cc0c8",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Create a datetime object with the Fringe date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cced2f1",
   "metadata": {},
   "source": [
    "#### Step 1 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6bf9220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the datetime object \n",
    "Fringe_date = dt.datetime(year = 2024, month = 8, day = 2, hour = 13, minute = 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf03608",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Create a countdown date object using arithmetic from the fringe datetime until now. This will be a `timedelta` data type, which represents the time between 2 `datetime` instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd452b",
   "metadata": {},
   "source": [
    "<details><summary style='color:darkblue'>HINT: Useful functions. CLICK HERE TO SEE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "Use one the `dt.datetime` functions to get the date and time now, rather than hard coding it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19238f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b9cef",
   "metadata": {},
   "source": [
    "#### Step 2 solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4aaa9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown = Fringe_date - dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72fab806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(countdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e8b4c",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Write an interpolating character string which will take our countdown object and tell us how many days until Fringe! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef5c613",
   "metadata": {},
   "source": [
    "#### Step 3 solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "398867fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countdown to Fringe 2024: 91 days, 0:03:27.312009\n"
     ]
    }
   ],
   "source": [
    "print(f\"Countdown to Fringe 2024: {countdown}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c98863",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "We have a minumum viable product (MVP) for our task, which is great! *BUT* we can improve our countdown accuracy using timezones (i.e., aware objects)! Let's say we want a countdown specifically for someone living in California in the United States.  \n",
    "\n",
    "Create a second datetime object for the Fringe date and set the correct time zone (i.e., Edinburgh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830282e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c73afa8",
   "metadata": {},
   "source": [
    "#### Step 4 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ca5d734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the timezone \n",
    "Fringe_date0 = Fringe_date.replace(tzinfo = tz.gettz(\"Europe/London\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "564e4de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 8, 2, 13, 35, tzinfo=tzfile('/usr/share/zoneinfo/Europe/London'))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fringe_date0 # confirm the object is now aware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "086865ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BST'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fringe_date0.tzname() # great, BST as expected "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32026044",
   "metadata": {},
   "source": [
    "### Step 5 \n",
    "\n",
    "Now create a datetime object for the now time in California"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698fef30",
   "metadata": {},
   "source": [
    "<details><summary style='color:darkblue'>HINT: Useful functions. CLICK HERE TO SEE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "* Use one of the timezone `tz` functions we learned about to create time zones not reported by your system\n",
    "* Use one the `dt.datetime` functions to get the date and time now, rather than hard coding it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2286fc90",
   "metadata": {},
   "source": [
    "#### Step 5 solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "def0499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_tz = tz.gettz(\"America/Los_Angeles\")\n",
    "now0 = dt.datetime.now(tz = LA_tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e78e0b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 5, 3, 4, 31, 55, 178936, tzinfo=tzfile('/usr/share/zoneinfo/America/Los_Angeles'))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm now0 is aware \n",
    "now0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c1e2ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PDT'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now0.tzname() # great, PDT as expected "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a7152",
   "metadata": {},
   "source": [
    "### Step 6 \n",
    "\n",
    "Now we are ready again to create a second countdown date object using arithmetic with the aware datetime objects we have create for the fringe until now (in California, USA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee67c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2036f0",
   "metadata": {},
   "source": [
    "#### Step 6 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "277fdb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown2 = Fringe_date0 - now0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adbfb81",
   "metadata": {},
   "source": [
    "### Step 7 \n",
    "\n",
    "Final step, write an interpolating character string which will take our countdown object and tell us how many days until Fringe! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e78bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a8a24",
   "metadata": {},
   "source": [
    "#### Step 7 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d064c267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countdown to Fringe 2024 from California, USA: 91 days, 1:03:04.821064\n"
     ]
    }
   ],
   "source": [
    "print(f\"Countdown to Fringe 2024 from California, USA: {countdown2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23771ef2",
   "metadata": {},
   "source": [
    "### Bonus \n",
    "\n",
    "When creating date, time, or datetime objects, you can use the `parser.parse()` function from `dateutil` which takes a string and parses (reads) the date into Python for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9cc4c210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01 01:00:00\n"
     ]
    }
   ],
   "source": [
    "## for example \n",
    "example_date = parser.parse(\"1 January 2024 1:00AM\")\n",
    "\n",
    "print(example_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc10355a",
   "metadata": {},
   "source": [
    "### Step 8 \n",
    "\n",
    "Put it all together and instead of Fringe, use your next birthday! If you want to use aware datetime objects, guess which timezone you may be in on your birthday. Be sure to update the interpolating string to reflect the new countdown event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ddac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cfd802",
   "metadata": {},
   "source": [
    "#### Step 8 Solution \n",
    "\n",
    "My birthday is on July 4th, so I have provided an example solution with that date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59146932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birthday Countdown: 61 days, 11:27:03.141301\n"
     ]
    }
   ],
   "source": [
    "# create tz object \n",
    "EDI_tz = tz.gettz(\"Europe/London\")\n",
    "\n",
    "# create bday object \n",
    "Bday = parser.parse(\"July 4 2024, 00:00\")\n",
    "\n",
    "# make it aware \n",
    "Bday0 = Bday.replace(tzinfo = EDI_tz)\n",
    "\n",
    "# create now dt object and make it aware\n",
    "now1 = dt.datetime.now(tz = EDI_tz)\n",
    "\n",
    "# create countdown object \n",
    "Bday_countdown = Bday0 - now1\n",
    "\n",
    "# print \n",
    "print(f\"Birthday Countdown: {Bday_countdown}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc7003",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Well done! ðŸŽ‰ \n",
    "\n",
    "Well done! You have completed all of the tasks for the Python notebook for this tutorial. If you have not done so yet, now move to the R notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485566c",
   "metadata": {},
   "source": [
    "---\n",
    "*Dr. Brittany Blankinship (2024)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
